import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam
from sklearn.cluster import KMeans
import numpy as np
from methods.zoomnext.shufflenetv2 import shufflenet_v2_x1_0


# è½»é‡åŒ–åˆ†ç±»æ¨¡å‹
# def train_and_predict(data, n_clusters=10, device='cpu'):
#     """è®­ç»ƒèšç±»æ¨¡å‹å¹¶è¿”å›é¢„æµ‹ç»“æœ"""
#     model = shufflenet_v2_x1_0().to(device) # 1. åˆå§‹åŒ–æ¨¡å‹å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
#     if isinstance(data, torch.Tensor):
#         data = data.to(device)  # 2. ç¡®ä¿æ•°æ®ä¹Ÿåœ¨åŒä¸€è®¾å¤‡ä¸Š
#     else:
#         data = torch.tensor(data).to(device) # å¦‚æœdataæ˜¯å…¶ä»–ç±»å‹(å¦‚numpyæ•°ç»„)ï¼Œå…ˆè½¬æ¢ä¸ºtensor
#     # 3. æå–ç‰¹å¾
#     with torch.no_grad():
#         features = model(data).cpu().numpy()  # è®¡ç®—å®Œæˆåç§»å›CPUå¹¶è½¬æ¢ä¸ºnumpy
#     # 4. è®­ç»ƒK-means
#     kmeans = KMeans(n_clusters=n_clusters, random_state=42)
#     kmeans.fit(features)  # è®­ç»ƒ
#     # 5. é¢„æµ‹ç±»åˆ«
#     cluster_ids = kmeans.predict(features)
#     return model, kmeans, cluster_ids



# def unsupervised_clustering(data, n_clusters=10):
#     # 1. åˆå§‹åŒ–æ¨¡å‹
#     model = LightweightAE()
#     model.to("cuda")
#
#     # 2. è®­ç»ƒè‡ªç¼–ç å™¨
#     print("Training Autoencoder...")
#     train_ae(model, data)
#
#     # 3. æå–ç‰¹å¾
#     with torch.no_grad():
#         data = data.to("cuda")
#         features = model.encoder(data)
#         print("Encoder è¾“å‡ºå½¢çŠ¶:", features.shape)  # æ£€æŸ¥ç»´åº¦
#
#         # å¼ºåˆ¶å±•å¹³ï¼šç¡®ä¿ (B, C, H, W) â†’ (B, C*H*W)
#         features_flat = features.reshape(features.size(0), -1).cpu().numpy()
#         print("å±•å¹³å NumPy æ•°ç»„å½¢çŠ¶:", features_flat.shape)  # åº”è¯¥æ˜¯ (B, D)
#
#     # 4. K-meansèšç±»
#     print("Performing K-means clustering...")
#     kmeans = KMeans(n_clusters=n_clusters, random_state=42)
#     clusters = kmeans.fit_predict(features_flat)  # è¾“å…¥å¿…é¡»æ˜¯ (n_samples, n_features)
#
#     return model, kmeans, clusters


import torch.optim as optim
from tqdm import tqdm  # ç”¨äºæ˜¾ç¤ºè®­ç»ƒè¿›åº¦


def train_and_predict(data, n_clusters=10, device='cpu',
                      mode='feature_extraction', epochs=10,
                      lr=0.001, batch_size=32):

    model = shufflenet_v2_x1_0().to(device)

    if not isinstance(data, torch.Tensor):
        data = torch.tensor(data, dtype=torch.float32)

    if mode == 'feature_extraction':
        with torch.no_grad():
            data = data.to(device)
            features = model(data).cpu().numpy()

        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        kmeans.fit(features)
        cluster_ids = kmeans.predict(features)

        return model, kmeans, cluster_ids

    elif mode == 'end_to_end':
        # å‡†å¤‡æ•°æ®åŠ è½½å™¨
        dataset = torch.utils.data.TensorDataset(data)
        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)

        # å®šä¹‰ä¼˜åŒ–å™¨
        optimizer = optim.Adam(model.parameters(), lr=lr)

        # è®­ç»ƒå¾ªç¯
        model.train()
        for epoch in range(epochs):
            progress_bar = tqdm(dataloader, desc=f'Epoch {epoch + 1}/{epochs}')
            for batch in progress_bar:
                inputs = batch[0].to(device)

                # å‰å‘ä¼ æ’­
                outputs = model(inputs)

                loss = torch.norm(outputs, p=2)  # ç¤ºä¾‹æŸå¤±ï¼Œå®é™…åº”æ ¹æ®ä»»åŠ¡ä¿®æ”¹

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                progress_bar.set_postfix(loss=loss.item())

        with torch.no_grad():
            model.eval()
            features = []
            for batch in dataloader:
                inputs = batch[0].to(device)
                features.append(model(inputs).cpu())
            features = torch.cat(features).numpy()

        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        kmeans.fit(features)
        cluster_ids = kmeans.predict(features)

        return model, kmeans, cluster_ids

    else:
        raise ValueError("æ¨¡å¼å¿…é¡»æ˜¯ 'feature_extraction' æˆ– 'end_to_end'")

class LiteDetector(nn.Module):
    def __init__(self, num_classes=1):
        super().__init__()
        # éª¨å¹²ç½‘ç»œ
        self.backbone = nn.Sequential(
            nn.Conv2d(3, 16, 3, 2, 1),  # [B,16,192,192]
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, 2, 1),  # [B,32,96,96]
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, 2, 1),  # [B,64,48,48]
            nn.ReLU()
        )

        # æ£€æµ‹å¤´
        self.head = nn.Sequential(
            nn.Conv2d(64, 64, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(64, (5 + num_classes) * 3, 1)  # 3ä¸ªanchor
        )

    def forward(self, x):
        x = self.backbone(x)
        return self.head(x)


class SimpleSegModel(nn.Module):
    def __init__(self, in_channels=3, out_channels=1):
        super().__init__()

        # ç¼–ç å™¨ (ä¸‹é‡‡æ ·)
        self.enc1 = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1,stride=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Conv2d(32, 32, 3, padding=1,stride=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        self.enc2 = nn.Sequential(
            nn.Conv2d(32, 64, 3, padding=1,stride=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(64, 64, 3, padding=1,stride=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        # è§£ç å™¨ (ä¸Šé‡‡æ ·)
        self.dec1 = nn.Sequential(
            nn.Conv2d(64, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        )

        self.dec2 = nn.Sequential(
            nn.Conv2d(32, 16, 3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.Conv2d(16, out_channels, 1),
            nn.Sigmoid()  # è¾“å‡º[0,1]çš„æ¦‚ç‡å›¾
        )

    def forward(self, x):
        # ç¼–ç 
        x1 = self.enc1(x)  # [B,32,H/2,W/2]
        x2 = self.enc2(x1)  # [B,64,H/4,W/4]

        # è§£ç 
        x = self.dec1(x2)  # [B,32,H/2,W/2]
        x = self.dec2(x)  # [B,C,H,W]

        return x

def full_pipeline(input_data, cluster_model, kmeans, det_models, seg_model):

    with torch.no_grad():
        features = cluster_model(input_data)  # ç°åœ¨è¾“å‡º [B,32]

    # è½¬æ¢ä¸ºnumpyå¹¶ç¡®ä¿æ˜¯2D
    features_np = features.cpu().numpy()
    if features_np.ndim > 2:
        features_np = features_np.reshape(features_np.shape[0], -1)  # å¼ºåˆ¶å±•å¹³

    cluster_ids = kmeans.predict(features_np)  # è¾“å…¥å½¢çŠ¶ [B, n_features]

    results = []
    for img, cls_id in zip(input_data, cluster_ids):
        # ç¬¬äºŒæ­¥ï¼šé€‰æ‹©å¯¹åº”æ£€æµ‹æ¨¡å‹
        det_model = det_models[cls_id % len(det_models)]

        # ç›®æ ‡æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        with torch.no_grad():
            pred = det_model(img.unsqueeze(0))
            bbox = non_max_suppression(pred)[0][0][:4].int()  # å‡è®¾çš„æ£€æµ‹è¾“å‡º

        # ç¬¬ä¸‰æ­¥ï¼šè£å‰ª
        x1, y1, x2, y2 = bbox.tolist()
        cropped = img[:, max(0, y1):min(img.shape[1], y2),
                  max(0, x1):min(img.shape[2], x2)]  # æ·»åŠ è¾¹ç•Œä¿æŠ¤

        # ç¬¬å››æ­¥ï¼šåˆ†å‰²
        with torch.no_grad():
            seg_input = F.interpolate(cropped.unsqueeze(0), size=256)
            mask = seg_model(seg_input)

        results.append({
            'class': cls_id,
            'bbox': bbox.tolist(),
            'mask': mask.squeeze().cpu().numpy()
        })

    return results


# è¾…åŠ©å‡½æ•°ï¼ˆç®€åŒ–ç‰ˆNMSï¼‰
def non_max_suppression(pred, conf_thres=0.5):
    # å®ç°ç®€åŒ–çš„NMS
    return [torch.tensor([[0, 0, 100, 100, 0.9]])]  # ç¤ºä¾‹è¿”å›

import os
import matplotlib.pyplot as plt
from matplotlib import rcParams
from datetime import datetime


def visualize_clusters(data, clusters, n_clusters=10, save_dir="cluster_results"):

    os.makedirs(save_dir, exist_ok=True)

    # ä¸“ä¸šçº§è¾“å‡ºé…ç½®
    rcParams.update({
        'figure.dpi': 300,
        'savefig.dpi': 300,
        'font.size': 7,
        'figure.titlesize': 8,
        'axes.titlepad': 4
    })

    # æ•°æ®é¢„å¤„ç†ï¼ˆæ”¯æŒTensorå’Œå­—å…¸è¾“å…¥ï¼‰
    if isinstance(data, torch.Tensor):
        images = data.permute(0, 2, 3, 1).cpu().numpy()
    elif isinstance(data, dict):
        tensor_data = torch.stack(list(data.values())).cpu()
        images = tensor_data.permute(0, 2, 3, 1).numpy()
    else:
        raise ValueError("è¾“å…¥å¿…é¡»æ˜¯PyTorch Tensoræˆ–åŒ…å«Tensorçš„å­—å…¸")

    # æ™ºèƒ½å½’ä¸€åŒ–ï¼ˆå…¼å®¹å„ç§è¾“å…¥èŒƒå›´ï¼‰
    if images.dtype in (np.float32, np.float64):
        if images.max() > 1.0: images /= 255.0
        images = np.clip(images, 0, 1)
    elif images.dtype == np.uint8:
        images = images.astype(np.float32) / 255.0

    # åŸºäºåŸå§‹å°ºå¯¸çš„åŠ¨æ€ç”»å¸ƒè®¡ç®—
    img_height = images.shape[1] / 80  # æ ‡å‡†åŒ–ç³»æ•°
    figsize = (img_height * 2.2, img_height * 2.2)  # é»„é‡‘æ¯”ä¾‹

    # èšç±»å¯è§†åŒ–ä¿å­˜
    for cluster_id in range(n_clusters):
        cluster_indices = np.where(clusters == cluster_id)[0]
        if not len(cluster_indices): continue

        fig = plt.figure(figsize=figsize, dpi=300, facecolor='white')

        # ç»˜åˆ¶å­å›¾ï¼ˆä¼˜åŒ–å¸ƒå±€ï¼‰
        for i, idx in enumerate(cluster_indices[:4]):
            ax = fig.add_subplot(2, 2, i + 1)
            ax.imshow(images[idx],
                      interpolation='hanning',  # é«˜çº§æ’å€¼ç®—æ³•
                      aspect='equal')  # ä¿æŒåƒç´ æ–¹å½¢
            ax.axis('off')

        # ä¸“ä¸šçº§æ ‡é¢˜æ’ç‰ˆ
        plt.suptitle(
            f'Cluster {cluster_id}\n({len(cluster_indices)} samples)',
            y=0.92,
            fontsize=8,
            fontweight='bold'
        )

        # ä¿å­˜è®¾ç½®
        save_path = os.path.join(save_dir, f"cluster_{cluster_id}.png")
        plt.savefig(
            save_path,
            bbox_inches='tight',
            pad_inches=0.05,
            transparent=False,
            metadata={
                'CreationTime': datetime.now().isoformat(),
                'Software': 'Matplotlib/Seaborn'
            }
        )
        plt.close(fig)

    print(f"ğŸ–¼ï¸ ä¸“ä¸šçº§å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³:\n{os.path.abspath(save_dir)}")
